---
title: "Longitudinal Binary Model"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
```
## Description of Data and Research Question

The data comes from user fitbit data and includes variables such as step count, time spent in different activity levels, and sleep. The user is identified by a unique ID and is repeatedly observed across time (in days). The research question is:

> to determine if the number of steps taken by a user is related to whether or not they slept more than 7 hours that night.

This is a longitudinal binary model because the response variable is binary (slept more than 7 hours or not) and the data is longitudinal (repeated observations across time). The prediction will be a probability of sleeping more than 7 hours.

We will include a random intercept for each individual to account for the individual's "baseline" probability of sleeping more than 7 hours.

### Data Exploration

This looks at the Fitabase data. 

```{r}
activity_data <- read.csv("data/Fitabase Data 4.12.16-5.12.16/dailyActivity_merged.csv")
sleep_data <- read.csv("data/Fitabase Data 4.12.16-5.12.16/sleepDay_merged.csv")

activity_data$ActivityDate <- as.Date(activity_data$ActivityDate, format = "%m/%d/%Y")

# calculate the sleep binary for each day
sleep_data$sleep_binary <- ifelse(sleep_data$TotalMinutesAsleep > 7*60, 1, 0)
# cast the SleepDay to date from datetime and name ActivityDate
# first from char to datetime
sleep_data$SleepDay <- as.POSIXct(sleep_data$SleepDay, format = "%m/%d/%Y %I:%M:%S %p")
# then from datetime to date
sleep_data$ActivityDate <- as.Date(sleep_data$SleepDay)

print(str(activity_data))
print(str(sleep_data))
```

We join the data. 

```{r}
# join the data on ActivityDate and Id
data <- merge(
    activity_data,
    sleep_data,
    by = c("Id", "ActivityDate")
)

print(str(data))
```

We display the count of observations for each idividual.

```{r}
data %>%
    group_by(Id) %>%
    summarise(n = n()) %>%
    arrange(desc(n))
```

We see that we do not have a uniform numer of observations for each individual. 

Now we look at the other data that Juna found. 

```{r}
# read from data/clean
data <- read.csv("data/clean/daily_fitbit.csv")
data$sleep_binary <- if_else(data$sleep_duration_hr > 7, 1, 0)
str(data)
```

```{r}
data %>%
    group_by(id) %>%
    summarise(n = n()) %>%
    arrange(desc(n))
```


## Model Setup

### Random Intercept Model

Random intercept model. For subject iâ€™s jth observation, the random intercept model is defined as:

$$y_{ij} = \beta_0 + \beta_1x_{ij} + u_i + \epsilon_{ij}$$

where:

* $y_ij$ is the probability of sleeping more than 7 hours for subject i on day j
* $x_{ij}$ is the number of steps taken by subject i on day j
* $u_i$ is the random intercept for subject i
* $\epsilon_{ij} \sim N(0,\sigma_e^2)$ is the error term for subject i on day j

The matrix form of the model is:

$$Y = X\beta + ZU + \epsilon$$

where:

* $Y$ is the $n \times 1$ vector of responses
* $X$ is the $n \times p$ design matrix for the fixed effects
* $\beta$ is the $p \times 1$ vector of fixed effects
* $U$ is the $n \times 1$ vector of subject-specific intercepts
* $Z$ is the design matrix

$$Z = \begin{bmatrix} 
1 & 0 & \cdots & 0 \\
1 & 0 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1 \\
0 & 0 & \cdots & 1 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1 \\
\end{bmatrix}$$

### Probit Model

In our case, we follow Albert and Chib (1993, Note set II page 160) to represent bernoulli data as a latent variable model (equivalent to a probit model in the GLM frameworks).

We let $\zeta_i$ denote subjet i's latent variable:

$$y_i = \begin{cases} 1 & \text{if } \zeta_i > 0 \\ 0 & \text{if } \zeta_i \leq 0 \end{cases}$$

where $z_i \sim N(x_i^T\beta, 1)$ which is never observed. 

The likelihood for a single subject $i$ is then:

$$\mathbb{L}(y_i|\zeta_i,x_i,\beta)\propto 
\{1(\zeta_i>0)1(y_i=1) + 1(\zeta_i \leq 0)1(y_i=0)\} 
\exp{\left(
-\frac{1}{2}(\zeta_i - x_i^T\beta)^2
\right)}$$

In our case, unlike in Albert and Chib, we do not only have the $\beta$ parameter. We also have the random intercept parameter $u_i$ which we typically assume to have a prior $u_i \sim N(0, \sigma_u^2)$. Our choice of prior for $\beta$ determines the posterior distribution of $\beta$. We recall the bayesian relationship between the posterior and the likelihood:

$$p(\beta|y) \propto \mathbb{L}(y|\beta)\pi(\beta)\pi(u_i)$$.

### Priors

If we choose a non-informative prior $\pi(\beta)$ then we get the following posterior:

$$p(\beta|y) \propto \pi(\beta)\prod_{i=1}^n\mathbb{L}(y_i|\zeta_i,x_i,\beta)$$

We can also choose the prior for $\beta$ to conduct a ridge or lasso regression by choosing $\beta \sim N(0, \gamma)$ or $\beta \sim \text{Laplace}(0, \gamma)$ respectively.

# Derivation

Let $y_{ij}$ be the binary outcome for subject i (i = 1, ..., N) at time point j (j = 1, ..., T_i), where $y_{ij}$ = 1 if the subject slept for 7 hours or more and $y_ij$ = 0 otherwise. Let $x_{ij}$ be the step count variable for subject i at time point j.

Introduce a latent variable $\zeta_{ij}$ and a random intercept $u_i$, and define the model as follows:

$$\zeta_ij = x_{ij}^T\beta + u_i + \epsilon_{ij}$$

Here, $\beta$ is the regression coefficient associated with the step count variable, $u_i$ is the random intercept for subject i with $u_i \sim N(0, \sigma_u^2)$, and $\epsilon_{ij}$ is the independent and identically distributed error term with $\epsilon_{ij} \sim N(0, \sigma^2)$. $\sigma_u^2$ and $\sigma^2$ are the variances of the random intercept and error term, respectively.

The binary outcome, $y_{ij}$, is determined by the latent variable $\zeta_ij$ as follows:

$$y_{ij} = \begin{cases} 1 & \text{if } \zeta_{ij} > 0 \\ 0 & \text{if } \zeta_{ij} \leq 0 \end{cases}$$

To specify prior distributions For the Bayesian model, you need to specify prior distributions for $\beta$ and the variances $\sigma_u^2$ and $\sigma^2$. Assuming non-informative priors for the betas, we can consider the following priors:

* $p(\beta) \propto 1$ for a non-informative prior. 
* The random intercepts $u_i$ have a prior normal distribution: $u_i \sim N(0, \sigma^2)$, which implies $p(u_i|\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left(-\frac{u_i^2}{2\sigma^2}\right)$
* A prior distribution for the variance of the random intercepts: $p(\sigma^2)$. Wr can choose a non-informative prior for sigma squared, such as  $p(\sigma^2) \propto \frac{1}{\sigma^2}$.

The likelihood function for a single observation $y_ij$, given its latent variable $\zeta_{ij}$, step count $x_{ij}$, and coefficient $\beta$, is:

[comment]: <> ($$\mathbb{L}_{ij} = \begin{cases} N(\zeta_{ij}; x_{ij}^T\beta + u_i, \sigma^2)  & if y_{ij} = 1 \\ N(\zeta_{ij}; x_{ij}^T\beta + u_i, \sigma^2) & if y_{ij} = 0 \end{cases}$$)

$$\mathbb{L}(y_i|\zeta_i,x_i,\beta) \propto \left(1(\zeta_i>0)1(y_i=1) + 1(\zeta_i \leq 0)1(y_i=0)\right) \exp{\left(-\frac{1}{2}(\zeta_i - x_i^T\beta)^2\right)}$$

Considering all observations for subject i, the likelihood for subject i is:

$$\mathbb{L}(y|\zeta,X,\beta) = \prod_{i=1}^N \mathbb{L}(y_i|\zeta_i,x_i,\beta)$$

Combining the likelihood function and the prior distributions, we get the joint distribution as:

$$p(y, \zeta, \beta, u, \sigma^2 | X) \propto \mathbb{L}(y|\zeta,X,\beta) \times p(\beta) \times p(u|\sigma^2) \times p(\sigma^2)$$

Multiplying this out we get:

$$p(y, \zeta, \beta, u, \sigma^2 | X) \propto \prod_{i=1}^N \left(
1(\zeta_i>0)1(y_i=1) + 1(\zeta_i \leq 0)1(y_i=0)\right) \exp{\left(-\frac{1}{2}(\zeta_i - x_i^T\beta)^2\right)}
\times 1 \times \frac{1}{\sqrt{2\pi\sigma^2}} \exp{\left(-\frac{u_i^2}{2\sigma^2}\right)} \times \frac{1}{\sigma^2}$$

$$= \prod_{i=1}^N \left(
1(\zeta_i>0)1(y_i=1) + 1(\zeta_i \leq 0)1(y_i=0)\right) 
\exp{\left(-\frac{1}{2}(\zeta_i - x_i^T\beta)^2\right)}
\times {(\sigma^2)}^{-3/2} \exp{\left(-\frac{u_i^2}{2\sigma^2}\right)}$$

$$= \prod_{i=1}^N \left(
1(\zeta_i>0)1(y_i=1) + 1(\zeta_i \leq 0)1(y_i=0)\right) 
\exp{\left(-\frac{1}{2}(\zeta_i - x_i^T\beta)^2 -\frac{u_i^2}{2\sigma^2}\right)}
\times {(\sigma^2)}^{-3/2}$$

To obtain the posterior distribution $p(\beta, u, \sigma^2 | y, X)$, we integrate out $\zeta$ from the joint distribution:

$$p(\beta, u, \sigma^2 | y, X) \propto \int p(y, \zeta, \beta, u, \sigma^2 | X) , d\zeta$$

This integration does not have a closed-form solution, so we would typically rely on a sampling algorithm, such as Markov Chain Monte Carlo (MCMC) methods, to estimate the posterior distribution and obtain parameter estimates.

# Computing

```{r}
# Load required libraries
library(MASS) # for multivariate normal functions
library(coda) # for mcmc objects
library(mcmcplots) # for mcmcplot
library(truncnorm) # for truncated normal functions
```

```{r}
# get the obs count per ID
obs <- data %>%
    group_by(id) %>%
    summarise(n = n()) %>%
    arrange(desc(n)) 

obs
```

```{r}
cols_to_remove <- c("id","date","sleep_duration_hr","sleep_binary")
model_data <- data[,!(names(data) %in% cols_to_remove)]
dim(model_data)
head(model_data)
```
```{r}
# use our data
set.seed(123)
IDs <- unique(data$id)
N <- nrow(model_data)
nGroups <- length(IDs)
p <- ncol(model_data)
X <- cbind(1, as.matrix(model_data))

# design matrix D that maps the U random intercepts to the observations for each individual
# D is a block diagonal matrix with nGroups blocks where each block has a vector of 1s of length n_i
# for each individual i generate a matrix where the column i is a vector of 1s of length n_i
# first creatre a matrix of 0s of size N x nGroups
D <- matrix(0, N, nGroups)
for (i in 1:nGroups) {
  # column i is a vector of 1s of length n_i
  # n_i is the number of observations for individual i
  # determined using obs
  n_i <- sum(data$id == IDs[i])
  D[which(data$id == IDs[i]), i] <- rep(1, n_i)
}

y1 <- data$TotalMinutesAsleep # continuous outcome
y <- data$sleep_binary # binary outcome
```

```{r}
# Define prior parameters
#prior_beta_mean <- rep(0, p)
#prior_beta_cov <- diag(p)
#prior_u_mean <- rep(0, nGroups)
#prior_u_cov <- diag(nGroups)
#prior_z_mean <- 0
#prior_z_sd <- 1
#prior_tau_shape <- 2
#prior_tau_rate <- 1
```

```{r}
# Number of iterations and burn-in
niter <- 5000
burnin <- 1000
```

```{r}
# Initialize arrays to store samples
beta_samples <- matrix(NA, nrow = niter, ncol = p+1)
u_samples <- matrix(NA, nrow = niter, ncol = nGroups)
tau_samples <- rep(NA, niter)
z_samples <- matrix(NA, nrow = niter, ncol = N)
```

```{r}
# Initialize starting values, which are matrices of 0s
beta <- matrix(0, p, 1)
u <- matrix(0, nGroups, 1)
z <- matrix(0, N, 1)
tau <- 1
```

```{r}
# loop over the number of iterations
for (i in 1:niter) {
  # Sample beta using MVN
  beta_mu <- solve(t(X) %*% X) %*% t(X) %*% (z - D %*% u)
  beta_sigma <- solve(t(X) %*% X)
  beta <- mvrnorm(n = 1, mu = beta_mu, Sigma = beta_sigma)

  # Sample U using MVN
  I <- diag(nGroups)
  u_mu <- solve(t(D) %*% D + tau * I) %*% t(D) %*% (z - X %*% beta)
  u_sigma <- solve(t(D) %*% D + tau * I)
  u <- mvrnorm(n = 1, mu = u_mu, Sigma = u_sigma)

  # Sample tau using gamma
  tau_shape <- nGroups/2
  tau_rate <- 1/2 * sqrt(sum(u^2))
  tau <- rgamma(n = 1, shape = tau_shape, rate = tau_rate)

  # sample z using truncated normal
  z_sd = 1
  z_mean = X %*% beta + D %*% u 
  # TODO - how to condition on y? 
  z <- if_else(y == 1, 
    rtruncnorm(n = 1, a=0, b=Inf, mean = z_mean, sd = 1),
    rtruncnorm(n = 1, a=-Inf, b=0, mean = z_mean, sd = 1))

  # Store samples
  beta_samples[i, ] <- beta
  u_samples[i, ] <- u
  z_samples[i, ] <- z
  tau_samples[i] <- tau
}
```

```{r}
# Combine samples into an mcmc object
tau_samples <- matrix(tau_samples)
# first name the columns of each
colnames(beta_samples) <- paste0("beta_", 1:(p+1))
colnames(u_samples) <- paste0("u_", 1:nGroups)
colnames(tau_samples) <- "tau"
colnames(z_samples) <- paste0("z_", 1:N)
samples <- cbind(beta_samples, u_samples, tau_samples, z_samples)
samples_mcmc <- as.mcmc(samples[-(1:burnin), ]) # Remove burn-in samples
```
```{r}
# Visualize convergence using mcmcplot
mcmcplot(samples_mcmc)
mcmcplot(samples_mcmc[, 1:5])
```


```{r}
# Visualize posterior distributions
var <- "u_1"
hist(samples_mcmc[, var], main = var)
```

```{r}
beta_df <- as.data.frame(beta_samples)
summary(beta_df)
```

Convergence of the algorithm aside from inspection. 

```{r}
# Geweke diagnostic
geweke_dig_data <- geweke.diag(samples_mcmc)
```

```{r}
# Gelman-Rubin statistic
# didn't do multiple chains
# gelman_rubin_data <- gelman.diag(samples_mcmc)

```